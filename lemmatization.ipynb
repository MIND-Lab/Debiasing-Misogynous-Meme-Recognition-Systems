{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import spacy_stanza\n",
    "import string\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('./Data/training.xls')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatization_stanza(texts):\n",
    "    \"\"\" Apply lemmatization with post tagging operations through Stanza.\n",
    "    Lower case \"\"\"\n",
    "    stanza.download(\"en\")\n",
    "    nlp = spacy_stanza.load_pipeline(\"en\")\n",
    "    processed_text = []\n",
    "\n",
    "    for testo in texts:\n",
    "        rev = []\n",
    "        testo = re.sub('#', '', testo) # remove @ and #\n",
    "        testo = re.sub('@', '', testo)\n",
    "        testo = testo.lower()\n",
    "\n",
    "        doc = nlp(testo)\n",
    "        for token in doc:\n",
    "            rev.append(token.lemma_)\n",
    "\n",
    "        rev = str(rev).replace(\"'\", '').replace(\",\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\\"\", '')\n",
    "        processed_text.append(rev)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatization_stanza_domains(texts):\n",
    "    \"\"\" Apply lemmatization with post tagging operations through Stanza.\n",
    "    Lower case \"\"\"\n",
    "    stanza.download(\"en\")\n",
    "    nlp = spacy_stanza.load_pipeline(\"en\")\n",
    "    processed_text = []\n",
    "\n",
    "    for testo in texts:\n",
    "\n",
    "        rev = []\n",
    "        testo = re.sub('@', '', testo) # remove @ and #\n",
    "        testo = re.sub('#', '', testo)\n",
    "        testo = testo.lower()\n",
    "\n",
    "        #deal with domains\n",
    "        if re.search(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?', testo):\n",
    "            subtext=[]\n",
    "            beginning=0\n",
    "            end=0\n",
    "            for e in re.finditer(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?', testo):\n",
    "                subtext.append(testo[beginning:e.start()])\n",
    "                subtext.append(e.group())\n",
    "                beginning= e.end()\n",
    "            subtext.append(testo[beginning:])\n",
    "            for sequence in subtext: \n",
    "                doc = nlp(sequence)\n",
    "                for token in doc:\n",
    "                    rev.append(token.lemma_)\n",
    "            rev = str(rev).replace(\"'\", '').replace(\",\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\\"\", '')\n",
    "            processed_text.append(rev)\n",
    "        \n",
    "        else:\n",
    "            doc = nlp(testo)\n",
    "            for token in doc:\n",
    "                rev.append(token.lemma_)\n",
    "            rev = str(rev).replace(\"'\", '').replace(\",\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\\"\", '')\n",
    "            processed_text.append(rev)\n",
    "\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmatized'] = apply_lemmatization_stanza(data['Text Transcription'])\n",
    "data.to_csv('Lemmatized/lemmatized_spacy.csv', sep='\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ProjEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "036d5e79b2f89acf0b2080b6b489e4897d66fffe68690462bc44e5a56924deac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
