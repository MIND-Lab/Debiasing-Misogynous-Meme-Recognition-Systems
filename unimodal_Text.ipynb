{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal Text\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img align=\"left\" src=\"Images\\unimodal-Text.png\" width=\"600\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import load_data, preprocessing, model_performances\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 222\n",
    "np.random.seed(seed) # numpy seed\n",
    "tf.random.set_seed(seed) # works for all devices (CPU and GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________________Utils ___________________________________________________\n",
    "if not os.path.exists('./Unimodal/predictions'):\n",
    "    os.makedirs('./Unimodal/predictions')\n",
    "\n",
    "if not os.path.exists('./Unimodal/performances'):\n",
    "    os.makedirs('./Unimodal/performances')\n",
    "\n",
    "path_models = './Unimodal/models'\n",
    "file_out = './Unimodal/performances/Text_results_10Fold.txt'\n",
    "predictions_csv_path = './Unimodal/predictions/Text_pred_10Fold.csv'\n",
    "\n",
    "file = open(file_out, 'a+')\n",
    "file.truncate(0)  # erase file content\n",
    "file.close()\n",
    "\n",
    "label_column = \"misogynous\"\n",
    "input_columns = ['text_USE']\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 512  # 512-length array with Universal Sentence Encoder algorithm\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________________load training data ___________________________________________________\n",
    "meme_df = load_data.load_training_data()\n",
    "\n",
    "meme_df['text_USE'] = preprocessing.use_preprocessing(meme_df, 'Text Transcription')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>Text Transcription</th>\n",
       "      <th>text_USE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5827.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>*Gets on Pornhub* Woman on Porn Ad: \"Are you s...</td>\n",
       "      <td>[0.04223586246371269, -0.028678087517619133, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2454.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>When your high school girlfriend finally turns...</td>\n",
       "      <td>[-0.016387682408094406, -0.004176544025540352,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6492.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Me every time I refuse to objectify women I ca...</td>\n",
       "      <td>[0.011072046123445034, -0.023999786004424095, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2054.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Verizon Q Search News r/kotakuinaction2 There ...</td>\n",
       "      <td>[-0.02618846856057644, -0.034125760197639465, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5388.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>me watching a horror movie NO DUDE WASN'T ME s...</td>\n",
       "      <td>[-0.0059230634942650795, 0.006091502029448748,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous                                 Text Transcription  \\\n",
       "0  5827.jpg           0  *Gets on Pornhub* Woman on Porn Ad: \"Are you s...   \n",
       "1  2454.jpg           0  When your high school girlfriend finally turns...   \n",
       "2  6492.jpg           1  Me every time I refuse to objectify women I ca...   \n",
       "3  2054.jpg           1  Verizon Q Search News r/kotakuinaction2 There ...   \n",
       "4  5388.jpg           0  me watching a horror movie NO DUDE WASN'T ME s...   \n",
       "\n",
       "                                            text_USE  \n",
       "0  [0.04223586246371269, -0.028678087517619133, 0...  \n",
       "1  [-0.016387682408094406, -0.004176544025540352,...  \n",
       "2  [0.011072046123445034, -0.023999786004424095, ...  \n",
       "3  [-0.02618846856057644, -0.034125760197639465, ...  \n",
       "4  [-0.0059230634942650795, 0.006091502029448748,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Fold on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________________train model on training data 10Fold________________________________________\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "iteration = 0\n",
    "real_values = np.array([])\n",
    "predict_values = np.array([])\n",
    "ids = np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(meme_df):  # split into train and test\n",
    "    preprocessing.set_seed(iteration)\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = preprocessing.elaborate_data_10fold(meme_df, \n",
    "                                                                               train_index,\n",
    "                                                                               test_index, \n",
    "                                                                               iteration,\n",
    "                                                                               input_columns, \n",
    "                                                                               label_column)\n",
    "    \n",
    "    model, history = model_performances.get_trained_model(x_train, \n",
    "                            y_train, \n",
    "                            x_val, \n",
    "                            y_val,\n",
    "                            input_shape=embed_size, \n",
    "                            activation_function='LeakyReLU', \n",
    "                            neurons=embed_size/2, \n",
    "                            dropout=0.2, \n",
    "                            epochs=100)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "\n",
    "    # un-comment to save each model\n",
    "    #model_name = path_models + 'unimodal_text_' + str(iteration)\n",
    "    #model.save(model_name)\n",
    "\n",
    "    # make prediction on training data\n",
    "    pred = model.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "    predict_values = np.append(predict_values, pred)\n",
    "    real_values = np.append(real_values, y_test)\n",
    "    ids = np.append(ids, meme_df.iloc[test_index, :]['file_name'].tolist())\n",
    "\n",
    "    result_df = meme_df.iloc[test_index, [0, 1]]\n",
    "    result_df['score_col'] = pred\n",
    "\n",
    "    # write on file\n",
    "    file = open(file_out, \"a+\")\n",
    "    file.write('\\n\\nITERAZIONE ' + str(iteration) + '\\n')\n",
    "    file.write(json.dumps(model_performances.compute_confusion_rates(result_df, 'score_col', 'misogynous', threshold)))\n",
    "    file.write('\\n') \n",
    "    file.write(classification_report(result_df['misogynous'].values, (result_df['score_col']>threshold).astype(int).values, target_names=['not_mis','mis']))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,585\n",
      "Trainable params: 131,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results dataframe, save predictions\n",
    "result_df = pd.DataFrame({'id': ids, 'real': real_values.astype(int), 'pred': predict_values})\n",
    "result_df.to_csv(predictions_csv_path, index=False, sep='\\t')\n",
    "\n",
    "# Overall metrics _ write on file\n",
    "file = open(file_out, \"a+\")\n",
    "file.write('\\n\\n10 Fold Results ' + str(iteration) + '\\n')\n",
    "file.write(json.dumps(model_performances.compute_confusion_rates(result_df, 'pred', 'real', threshold)))\n",
    "file.write('\\n') \n",
    "file.write(classification_report(result_df['real'].values, (result_df['pred']>threshold).astype(int).values, target_names=['not_mis','mis']))\n",
    "file.write('\\n AUC:') \n",
    "file.write(str(model_performances.compute_auc(result_df['real'].values, result_df['pred'].values)))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 fold on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________________Utils ___________________________________________________\n",
    "if not os.path.exists('./Unimodal/predictionsTest'):\n",
    "    os.makedirs('./Unimodal/predictionsTest')\n",
    "\n",
    "if not os.path.exists('./Unimodal/performancesTest'):\n",
    "    os.makedirs('./Unimodal/performancesTest')\n",
    "\n",
    "path_models = './Unimodal/modelsTest'\n",
    "file_out = './Unimodal/performancesTest/Text_results_10Fold.txt'\n",
    "predictions_csv_path = './Unimodal/predictionsTest/Text_pred_10Fold.csv'\n",
    "\n",
    "file = open(file_out, 'a+')\n",
    "file.truncate(0)  # erase file content\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test and preprocessing\n",
    "test_df = load_data.load_test_data()\n",
    "test_df['text_USE'] = preprocessing.use_preprocessing(test_df, 'Text Transcription')\n",
    "\n",
    "x_test, y_test = preprocessing.elaborate_input(test_df, input_columns, label_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________________train model on training data 10Fold________________________________________\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "iteration = 0\n",
    "real_values = np.array([])\n",
    "predict_values = np.array([])\n",
    "ids = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(meme_df):  # split into train and test\n",
    "    preprocessing.set_seed(iteration)\n",
    "    x_train, y_train = preprocessing.elaborate_input(meme_df.iloc[train_index, :], input_columns, label_column)\n",
    "    x_val, y_val = preprocessing.elaborate_input(meme_df.iloc[val_index, :], input_columns, label_column)\n",
    "\n",
    "    model, history = model_performances.get_trained_model(x_train, \n",
    "                            y_train, \n",
    "                            x_val, \n",
    "                            y_val,\n",
    "                            input_shape=embed_size, \n",
    "                            activation_function='LeakyReLU', \n",
    "                            neurons=embed_size/2, \n",
    "                            dropout=0.2, \n",
    "                            epochs=100)\n",
    "\n",
    "    iteration = iteration + 1\n",
    "\n",
    "    # make prediction on training data\n",
    "    pred = model.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "    predict_values = np.append(predict_values, pred)\n",
    "    real_values = np.append(real_values, y_test)\n",
    "    ids = np.append(ids, test_df['file_name'].tolist())\n",
    "\n",
    "    result_df = test_df[['file_name', 'misogynous']].copy()\n",
    "    result_df['score_col'] = pred\n",
    "\n",
    "    print(result_df.columns)\n",
    "    # write on file\n",
    "    file = open(file_out, \"a+\")\n",
    "    file.write('\\n\\nITERAZIONE ' + str(iteration) + '\\n')\n",
    "    file.write(json.dumps(model_performances.compute_confusion_rates(result_df, 'score_col', 'misogynous', threshold)))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n') \n",
    "    file.write(classification_report(result_df['misogynous'].values, (result_df['score_col']>threshold).astype(int).values, target_names=['not_mis','mis']))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_label': 1,\n",
       " 'tpr': 0.848,\n",
       " 'tnr': 0.4294,\n",
       " 'fpr': 0.5706,\n",
       " 'fnr': 0.15200000000000002,\n",
       " 'precision': 0.5977724517129565,\n",
       " 'recall': 0.848,\n",
       " 'accuracy': 0.6387,\n",
       " 'f1': 0.7012321177540726,\n",
       " 'auc': 0.725758}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results dataframe, save predictions\n",
    "result_df = pd.DataFrame({'id': ids, 'real': real_values.astype(int), 'pred': predict_values})\n",
    "result_df.to_csv(predictions_csv_path, index=False, sep='\\t')\n",
    "\n",
    "# Overall metrics _ write on file\n",
    "file = open(file_out, \"a+\")\n",
    "file.write('\\n\\n10 Fold Results ' + str(iteration) + '\\n')\n",
    "file.write(json.dumps(model_performances.compute_confusion_rates(result_df, 'pred', 'real', threshold)))\n",
    "file.write('\\n')\n",
    "file.write('\\n') \n",
    "file.write(classification_report(result_df['real'].values, (result_df['pred']>threshold).astype(int).values, target_names=['not_mis','mis']))\n",
    "file.write('\\n AUC:') \n",
    "file.write(str(model_performances.compute_auc(result_df['real'].values, result_df['pred'].values)))\n",
    "file.close()\n",
    "model_performances.compute_confusion_rates(result_df, 'pred', 'real', threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ProjEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "036d5e79b2f89acf0b2080b6b489e4897d66fffe68690462bc44e5a56924deac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
